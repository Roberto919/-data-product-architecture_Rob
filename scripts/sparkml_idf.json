{"paragraphs":[{"text":"%pyspark\n\nfrom pyspark.ml.feature import HashingTF, IDF, Tokenizer, CountVectorizer\n\n# Creamos nuestro set de entrada para formar la TDM\nsentence_data = spark.createDataFrame([\n    (0.0, \"Hi I heard about Spark\"),\n    (0.0, \"I wish Java could use case classes\"),\n    (1.0, \"Logistic regression models are neat\")\n], [\"label\", \"sentence\"])\n\n# Ocupamos el transformer Tokenizer para separar por palabras\ntokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n# Aqui no hay train! porque no estamos entrenando nanda... estamos en un problema\n# de IR. Tokenizer no tiene un metodo fit -no hay entrenamiento-\nwords_data = tokenizer.transform(sentence_data)\n\n# Ocupamos el transformer CountVectorizer para generar una matriz de \n# terminos y sus frecuencias \ncount_vectorizer = CountVectorizer(inputCol=\"words\", outputCol=\"raw_features\")\nfeaturized_model = count_vectorizer.fit(words_data)\nfeaturized_data = featurized_model.transform(words_data)\nfeaturized_data.show(truncate=False)\n\n","user":"anonymous","dateUpdated":"2020-03-31T22:14:39+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----+-----------------------------------+------------------------------------------+-----------------------------------------------------+\n|label|sentence                           |words                                     |raw_features                                         |\n+-----+-----------------------------------+------------------------------------------+-----------------------------------------------------+\n|0.0  |Hi I heard about Spark             |[hi, i, heard, about, spark]              |(16,[0,1,2,3,10],[1.0,1.0,1.0,1.0,1.0])              |\n|0.0  |I wish Java could use case classes |[i, wish, java, could, use, case, classes]|(16,[0,4,5,7,11,14,15],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n|1.0  |Logistic regression models are neat|[logistic, regression, models, are, neat] |(16,[6,8,9,12,13],[1.0,1.0,1.0,1.0,1.0])             |\n+-----+-----------------------------------+------------------------------------------+-----------------------------------------------------+\n\n"}]},"apps":[],"jobName":"paragraph_1585692497417_-1654665900","id":"20200331-220817_1843561123","dateCreated":"2020-03-31T22:08:17+0000","dateStarted":"2020-03-31T22:14:39+0000","dateFinished":"2020-03-31T22:14:48+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3354"},{"text":"%pyspark\n\n# Ocupamos IDF para obtener el IDF de la coleccion de documentos mock que \n# generamos. IDF si tiene un metodo fit a traves del cual le enviamos el set \n# de tokens al que queremos obtener el IDF\nidf = IDF(inputCol=\"raw_features\", outputCol=\"features\", minDocFreq=1)\n# Aqui obtenemos el modelo a ocupar (transformer) a ocupar \nidf_model = idf.fit(featurized_data)\nrescaled_data = idf_model.transform(featurized_data)\n\nrescaled_data.select(\"label\", \"features\").show(truncate=False)","user":"anonymous","dateUpdated":"2020-03-31T22:14:55+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1585692514480_-2051301179","id":"20200331-220834_176241334","dateCreated":"2020-03-31T22:08:34+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:3355","dateFinished":"2020-03-31T22:14:55+0000","dateStarted":"2020-03-31T22:14:55+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|label|features                                                                                                                                                       |\n+-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|0.0  |(16,[0,1,2,3,10],[0.28768207245178085,0.6931471805599453,0.6931471805599453,0.6931471805599453,0.6931471805599453])                                            |\n|0.0  |(16,[0,4,5,7,11,14,15],[0.28768207245178085,0.6931471805599453,0.6931471805599453,0.6931471805599453,0.6931471805599453,0.6931471805599453,0.6931471805599453])|\n|1.0  |(16,[6,8,9,12,13],[0.6931471805599453,0.6931471805599453,0.6931471805599453,0.6931471805599453,0.6931471805599453])                                            |\n+-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n"}]}},{"text":"%pyspark\n","user":"anonymous","dateUpdated":"2020-03-31T22:14:55+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1585692895100_-891290830","id":"20200331-221455_870224660","dateCreated":"2020-03-31T22:14:55+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3553"}],"name":"sparkml_ex3","id":"2F56DH6JF","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}